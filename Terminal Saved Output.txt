Last login: Tue Jan  7 15:10:51 on ttys000
rupeshande@Rupeshs-MacBook-Air ~ % ssh -ohostkeyalgorithms=ssh-rsa cloudera@192.168.64.4
cloudera@192.168.64.4's password: 
Last login: Tue Jan  7 01:35:24 2025 from 192.168.64.1
-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory
[cloudera@quickstart ~]$ ls
1          Templates                 enterprise-deployment.json
5???       Videos                    exportcopy.java
Desktop    apache-cassandra-3.11.10  express-deployment.json
Documents  atab.avsc                 hbase.sh
Downloads  atab.java                 lib
Music      cloudera-manager          prodata
Pictures   cm_api.py                 workspace
Public     data
[cloudera@quickstart ~]$ mkdir file1
[cloudera@quickstart ~]$ ls
1          Templates                 enterprise-deployment.json
5???       Videos                    exportcopy.java
Desktop    apache-cassandra-3.11.10  express-deployment.json
Documents  atab.avsc                 file1
Downloads  atab.java                 hbase.sh
Music      cloudera-manager          lib
Pictures   cm_api.py                 prodata
Public     data                      workspace
[cloudera@quickstart ~]$ touch write file 
[cloudera@quickstart ~]$ ls 
1          Public                    cm_api.py                   hbase.sh
5???       Templates                 data                        lib
Desktop    Videos                    enterprise-deployment.json  prodata
Documents  apache-cassandra-3.11.10  exportcopy.java             workspace
Downloads  atab.avsc                 express-deployment.json     write
Music      atab.java                 file
Pictures   cloudera-manager          file1
[cloudera@quickstart ~]$ echo write > myname 
[cloudera@quickstart ~]$ cat write 
[cloudera@quickstart ~]$ cat myname 
write
[cloudera@quickstart ~]$ ls
1          Public                    cm_api.py                   hbase.sh
5???       Templates                 data                        lib
Desktop    Videos                    enterprise-deployment.json  myname
Documents  apache-cassandra-3.11.10  exportcopy.java             prodata
Downloads  atab.avsc                 express-deployment.json     workspace
Music      atab.java                 file                        write
Pictures   cloudera-manager          file1
[cloudera@quickstart ~]$ rm file 
rm: remove regular empty file `file'? yes
[cloudera@quickstart ~]$ ls
1          Public                    cm_api.py                   lib
5???       Templates                 data                        myname
Desktop    Videos                    enterprise-deployment.json  prodata
Documents  apache-cassandra-3.11.10  exportcopy.java             workspace
Downloads  atab.avsc                 express-deployment.json     write
Music      atab.java                 file1
Pictures   cloudera-manager          hbase.sh
[cloudera@quickstart ~]$ rmr write
-bash: rmr: command not found
[cloudera@quickstart ~]$ #Hadoop commands begins...
[cloudera@quickstart ~]$ hadoop dfsadmin -safemode leave
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

Safe mode is OFF
[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera
Found 21 items
drwxr-xr-x   - cloudera supergroup          0 2024-11-25 03:44 /user/cloudera/_sqoop
drwxr-xr-x   - cloudera supergroup          0 2024-11-25 03:39 /user/cloudera/adir
drwxr-xr-x   - cloudera supergroup          0 2024-11-25 03:44 /user/cloudera/avrodata
drwxr-xr-x   - cloudera supergroup          0 2024-11-25 03:09 /user/cloudera/dynamicpartition
drwxr-xr-x   - cloudera supergroup          0 2024-11-25 02:27 /user/cloudera/helppartition2
drwxr-xr-x   - cloudera supergroup          0 2024-11-25 01:59 /user/cloudera/hive1
drwxr-xr-x   - cloudera supergroup          0 2024-11-25 02:08 /user/cloudera/partition1
drwxr-xr-x   - cloudera supergroup          0 2024-11-25 02:36 /user/cloudera/partition2
-rw-r--r--   1 cloudera supergroup          8 2024-11-13 20:27 /user/cloudera/passwordfile
drwxr-xr-x   - cloudera supergroup          0 2024-11-13 03:23 /user/cloudera/sqoop1
drwxr-xr-x   - cloudera supergroup          0 2024-11-13 20:03 /user/cloudera/sqoop10
drwxr-xr-x   - cloudera supergroup          0 2024-11-13 20:26 /user/cloudera/sqoop11
drwxr-xr-x   - cloudera supergroup          0 2024-11-13 20:33 /user/cloudera/sqoop12
drwxr-xr-x   - cloudera supergroup          0 2024-11-13 03:38 /user/cloudera/sqoop2
drwxr-xr-x   - cloudera supergroup          0 2024-11-13 03:59 /user/cloudera/sqoop3
drwxr-xr-x   - cloudera supergroup          0 2024-11-13 04:05 /user/cloudera/sqoop4
drwxr-xr-x   - cloudera supergroup          0 2024-11-13 05:35 /user/cloudera/sqoop5
drwxr-xr-x   - cloudera supergroup          0 2024-11-13 05:57 /user/cloudera/sqoop6
drwxr-xr-x   - cloudera supergroup          0 2024-11-13 06:30 /user/cloudera/sqoop7
drwxr-xr-x   - cloudera supergroup          0 2024-11-13 19:44 /user/cloudera/sqoop8
drwxr-xr-x   - cloudera supergroup          0 2024-11-13 19:55 /user/cloudera/sqoop9
[cloudera@quickstart ~]$ hadoop fs -rm -r /user/cloudera/
Deleted /user/cloudera
[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera/
ls: `/user/cloudera/': No such file or directory
[cloudera@quickstart ~]$ hadoop fs -mkdir /user/cloudera/
[cloudera@quickstart ~]$ hadoop fs -mkdir /user/cloudera/myfile
[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera
Found 1 items
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:01 /user/cloudera/myfile
[cloudera@quickstart ~]$ hadoop fs -mkdir -p /user/cloudera/folder1/folder2/folder3 #recursive folder creation 
[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera
Found 2 items
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:08 /user/cloudera/folder1
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:01 /user/cloudera/myfile
[cloudera@quickstart ~]$ hadoop fs -put /home/cloudera/file1 /user/cloudera
[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera
Found 3 items
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:09 /user/cloudera/file1
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:08 /user/cloudera/folder1
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:01 /user/cloudera/myfile
[cloudera@quickstart ~]$ hadoop fs -touchz /user/cloudera/datafile #creating empty text file 
[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera
Found 4 items
-rw-r--r--   1 cloudera supergroup          0 2025-01-07 02:11 /user/cloudera/datafile
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:09 /user/cloudera/file1
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:08 /user/cloudera/folder1
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:01 /user/cloudera/myfile
[cloudera@quickstart ~]$ echo I am Rupesh Phanindra Sai Ande > /home/cloudera/file1/mydatafile
[cloudera@quickstart ~]$ cat /home/cloudera/file1/mydatafile 
I am Rupesh Phanindra Sai Ande
[cloudera@quickstart ~]$ #ingeting local file(mydatafile) to hadoop (HDFS) location
[cloudera@quickstart ~]$ hadoop fs -put /home/cloudera/file1/mydatafile /user/cloudera/myfile 
[cloudera@quickstart ~]$ hadoop fs -cat /user/cloudera/myfile/mydatafile
I am Rupesh Phanindra Sai Ande
[cloudera@quickstart ~]$ #By using cat command above local file is read from hdfs location 
[cloudera@quickstart ~]$ echo Adding second line to the same file by using append command directly to hdfs location > /home/cloudera/mydata2
[cloudera@quickstart ~]$ cat mydata2
Adding second line to the same file by using append command directly to hdfs location
[cloudera@quickstart ~]$ #here using append commad 
[cloudera@quickstart ~]$ hadoop fs -appendToFile /home/cloudera/mydata2 /user/cloudera/myfile/mydatafile
[cloudera@quickstart ~]$ hadoop fs -cat /user/cloudera/myfile/mydatafile
I am Rupesh Phanindra Sai Ande
Adding second line to the same file by using append command directly to hdfs location
[cloudera@quickstart ~]$ #data has been added instead of overwriting the existing file data
[cloudera@quickstart ~]$ #to copy a file or dict directly form local to hdfs
[cloudera@quickstart ~]$ ls 
1          Public                    cm_api.py                   lib
5???       Templates                 data                        mydata2
Desktop    Videos                    enterprise-deployment.json  myname
Documents  apache-cassandra-3.11.10  exportcopy.java             prodata
Downloads  atab.avsc                 express-deployment.json     workspace
Music      atab.java                 file1                       write
Pictures   cloudera-manager          hbase.sh
[cloudera@quickstart ~]$ hadoop fs -copyFromLocal /home/cloudera/mydata2 /user/cloudera/
[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera
Found 5 items
-rw-r--r--   1 cloudera supergroup          0 2025-01-07 02:11 /user/cloudera/datafile
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:09 /user/cloudera/file1
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:08 /user/cloudera/folder1
-rw-r--r--   1 cloudera supergroup         86 2025-01-07 02:28 /user/cloudera/mydata2
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:18 /user/cloudera/myfile
[cloudera@quickstart ~]$ #what if I need to send an copy of file from hdfs to local system 
[cloudera@quickstart ~]$ hadoop fs -copyToLocal /user/cloudera/folder1 /home/cloudera
[cloudera@quickstart ~]$ ls 
1          Public                    cm_api.py                   hbase.sh
5???       Templates                 data                        lib
Desktop    Videos                    enterprise-deployment.json  mydata2
Documents  apache-cassandra-3.11.10  exportcopy.java             myname
Downloads  atab.avsc                 express-deployment.json     prodata
Music      atab.java                 file1                       workspace
Pictures   cloudera-manager          folder1                     write
[cloudera@quickstart ~]$ #here we got folder1 in the list of local files 
[cloudera@quickstart ~]$ #what if I need to send or get the data but that has to be deleted once after copying the data..., lets create a file now and will send to hdfs 
[cloudera@quickstart ~]$ echo Keeping some data to test the file deletion > fileDeletionCheck
[cloudera@quickstart ~]$ cat fileDeletionCheck
Keeping some data to test the file deletion
[cloudera@quickstart ~]$ #sending data to hdfs...
[cloudera@quickstart ~]$ hadoop fs -moveFromLocal /home/cloudera/fileDeletionCheck /user/cloudera

[cloudera@quickstart ~]$ 
[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera
Found 6 items
-rw-r--r--   1 cloudera supergroup          0 2025-01-07 02:11 /user/cloudera/datafile
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:09 /user/cloudera/file1
-rw-r--r--   1 cloudera supergroup         44 2025-01-07 02:33 /user/cloudera/fileDeletionCheck
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:08 /user/cloudera/folder1
-rw-r--r--   1 cloudera supergroup         86 2025-01-07 02:28 /user/cloudera/mydata2
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:18 /user/cloudera/myfile
[cloudera@quickstart ~]$ #here we have fileDeletionCheck, lets check we have content in it or not.. 
[cloudera@quickstart ~]$ hadoop fs -cat /user/cloudera/fileDeletionCheck
Keeping some data to test the file deletion
[cloudera@quickstart ~]$ #Here we 
Message from syslogd@quickstart at Jan  7 02:44:03 ...
 kernel:BUG: soft lockup - CPU#0 stuck for 133s! [java:7453]

Message from syslogd@quickstart at Jan  7 02:47:31 ...
 kernel:BUG: soft lockup - CPU#0 stuck for 79s! [java:7453]

[cloudera@quickstart ~]$ #Here we file in hdfs, lets check in local system we have that file or not, according to result it should deleted.. 
[cloudera@quickstart ~]$ ls 
1          Public                    cm_api.py                   hbase.sh
5???       Templates                 data                        lib
Desktop    Videos                    enterprise-deployment.json  mydata2
Documents  apache-cassandra-3.11.10  exportcopy.java             myname
Downloads  atab.avsc                 express-deployment.json     prodata
Music      atab.java                 file1                       workspace
Pictures   cloudera-manager          folder1                     write
[cloudera@quickstart ~]$ #here file got deleted.. 
[cloudera@quickstart ~]$ #what if I need to send data from hdfs to local, but after moving that file has to be deleted from hdfs location 
[cloudera@quickstart ~]$ hadoop fs -moveToLocal /user/cloudera/fileDeletionCheck /home/cloudera
moveToLocal: Option '-moveToLocal' is not implemented yet.
[cloudera@quickstart ~]$ #this version doesn't have this feature.. lets do it in newer versions of hadoop 
[cloudera@quickstart ~]$ hadoop fs -get /user/cloudera/fileDeletionCheck /home/cloudera
[cloudera@quickstart ~]$ #validating data in local 
[cloudera@quickstart ~]$ cat fileDeletionCheck
Keeping some data to test the file deletion
[cloudera@quickstart ~]$ #done...
[cloudera@quickstart ~]$ 
[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera
Found 6 items
-rw-r--r--   1 cloudera supergroup          0 2025-01-07 02:11 /user/cloudera/datafile
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:09 /user/cloudera/file1
-rw-r--r--   1 cloudera supergroup         44 2025-01-07 02:33 /user/cloudera/fileDeletionCheck
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:08 /user/cloudera/folder1
-rw-r--r--   1 cloudera supergroup         86 2025-01-07 02:28 /user/cloudera/mydata2
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:18 /user/cloudera/myfile
[cloudera@quickstart ~]$ hadoop fs -cp /user/cloudera/file1 /user/cloudera/folder1
[cloudera@quickstart ~]$ #internal copy in hdfs location, lets check in folder1 location either file1 data is copied or not 
[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera/folder1
Found 2 items
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 03:05 /user/cloudera/folder1/file1
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:08 /user/cloudera/folder1/folder2
[cloudera@quickstart ~]$ hadoop fs -ls -r /user/cloudera #to get all the files, folders, internal inside files and folders 
Found 6 items
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:18 /user/cloudera/myfile
-rw-r--r--   1 cloudera supergroup         86 2025-01-07 02:28 /user/cloudera/mydata2
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 03:05 /user/cloudera/folder1
-rw-r--r--   1 cloudera supergroup         44 2025-01-07 02:33 /user/cloudera/fileDeletionCheck
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:09 /user/cloudera/file1
-rw-r--r--   1 cloudera supergroup          0 2025-01-07 02:11 /user/cloudera/datafile
[cloudera@quickstart ~]$ hadoop fs -mv /user/cloudera/folder1/folder2/folder3 /user/cloudera/folder2 #moving means kind of deletion from existing location after copying data to new location
[cloudera@quickstart ~]$ hadoop fs -du /user/cloudera #disk usage 
0    0    /user/cloudera/datafile
0    0    /user/cloudera/file1
44   44   /user/cloudera/fileDeletionCheck
0    0    /user/cloudera/folder1
0    0    /user/cloudera/folder2
86   86   /user/cloudera/mydata2
117  117  /user/cloudera/myfile
[cloudera@quickstart ~]$ hadoop fs -df /user/cloudera/file1
Filesystem                              Size        Used    Available  Use%
hdfs://quickstart.cloudera:8020  58531520512  1453965312  44448239616    2%
[cloudera@quickstart ~]$ hadoop fs -stat %o /user/cloudera/fileDeletionCheck
134217728
[cloudera@quickstart ~]$ #above command tells about block size 134217728 bytes = 128 MB
[cloudera@quickstart ~]$ #to know about replication factor 
[cloudera@quickstart ~]$ hadoop fs -stat %r /user/cloudera/fileDeletionCheck
1
[cloudera@quickstart ~]$ #to set the replication factor 
[cloudera@quickstart ~]$ hadoop fs -setrep -w 3 /user/cloudera/fileDeletionCheck
Replication 3 set: /user/cloudera/fileDeletionCheck
Waiting for /user/cloudera/fileDeletionCheck ............................
................^C[cloudera@quickstart ~]$ 
[cloudera@quickstart ~]$ hadoop fs -stat %a /user/cloudera/fileDeletionCheck #last access time 
a
[cloudera@quickstart ~]$ hadoop fs -stat %b /user/cloudera/fileDeletionCheck # file size in bytes 
44
[cloudera@quickstart ~]$ hadoop fs -stat %n /user/cloudera/fileDeletionCheck #file name 
fileDeletionCheck
[cloudera@quickstart ~]$ hadoop fs -stat %y /user/cloudera/fileDeletionCheck #last modification time 
2025-01-07 10:33:39
[cloudera@quickstart ~]$ hadoop fs -stat %u /user/cloudera/fileDeletionCheck #username of the onwer 
cloudera
[cloudera@quickstart ~]$ hadoop fs -stat %r /user/cloudera/fileDeletionCheck #replication factor 
3
[cloudera@quickstart ~]$ #to check the health and condition of the system.. 
[cloudera@quickstart ~]$ hadoop fsck /user/cloudera/fileDeletionCheck -files
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

Connecting to namenode via http://quickstart.cloudera:50070/fsck?ugi=cloudera&files=1&path=%2Fuser%2Fcloudera%2FfileDeletionCheck
FSCK started by cloudera (auth:SIMPLE) from /127.0.0.1 for path /user/cloudera/fileDeletionCheck at Tue Jan 07 03:27:20 PST 2025
/user/cloudera/fileDeletionCheck 44 bytes, 1 block(s):  Under replicated BP-1914853243-127.0.0.1-1500467607052:blk_1073744586_3793. Target Replicas is 3 but found 1 live replica(s), 0 decommissioned replica(s), 0 decommissioning replica(s).
Status: HEALTHY
 Total size:	44 B
 Total dirs:	0
 Total files:	1
 Total symlinks:		0
 Total blocks (validated):	1 (avg. block size 44 B)
 Minimally replicated blocks:	1 (100.0 %)
 Over-replicated blocks:	0 (0.0 %)
 Under-replicated blocks:	1 (100.0 %)
 Mis-replicated blocks:		0 (0.0 %)
 Default replication factor:	1
 Average block replication:	1.0
 Corrupt blocks:		0
 Missing replicas:		2 (66.666664 %)
 Number of data-nodes:		1
 Number of racks:		1
FSCK ended at Tue Jan 07 03:27:20 PST 2025 in 43 milliseconds


The filesystem under path '/user/cloudera/fileDeletionCheck' is HEALTHY
[cloudera@quickstart ~]$ hadoop fsck /user/cloudera/fileDeletionCheck -blocks 
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

Connecting to namenode via http://quickstart.cloudera:50070/fsck?ugi=cloudera&blocks=1&path=%2Fuser%2Fcloudera%2FfileDeletionCheck
FSCK started by cloudera (auth:SIMPLE) from /127.0.0.1 for path /user/cloudera/fileDeletionCheck at Tue Jan 07 03:27:44 PST 2025
.
/user/cloudera/fileDeletionCheck:  Under replicated BP-1914853243-127.0.0.1-1500467607052:blk_1073744586_3793. Target Replicas is 3 but found 1 live replica(s), 0 decommissioned replica(s), 0 decommissioning replica(s).
Status: HEALTHY
 Total size:	44 B
 Total dirs:	0
 Total files:	1
 Total symlinks:		0
 Total blocks (validated):	1 (avg. block size 44 B)
 Minimally replicated blocks:	1 (100.0 %)
 Over-replicated blocks:	0 (0.0 %)
 Under-replicated blocks:	1 (100.0 %)
 Mis-replicated blocks:		0 (0.0 %)
 Default replication factor:	1
 Average block replication:	1.0
 Corrupt blocks:		0
 Missing replicas:		2 (66.666664 %)
 Number of data-nodes:		1
 Number of racks:		1
FSCK ended at Tue Jan 07 03:27:44 PST 2025 in 25 milliseconds


The filesystem under path '/user/cloudera/fileDeletionCheck' is HEALTHY
[cloudera@quickstart ~]$ hadoop fsck /user/cloudera/fileDeletionCheck -locations
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

Connecting to namenode via http://quickstart.cloudera:50070/fsck?ugi=cloudera&locations=1&path=%2Fuser%2Fcloudera%2FfileDeletionCheck
FSCK started by cloudera (auth:SIMPLE) from /127.0.0.1 for path /user/cloudera/fileDeletionCheck at Tue Jan 07 03:28:09 PST 2025
.
/user/cloudera/fileDeletionCheck:  Under replicated BP-1914853243-127.0.0.1-1500467607052:blk_1073744586_3793. Target Replicas is 3 but found 1 live replica(s), 0 decommissioned replica(s), 0 decommissioning replica(s).
Status: HEALTHY
 Total size:	44 B
 Total dirs:	0
 Total files:	1
 Total symlinks:		0
 Total blocks (validated):	1 (avg. block size 44 B)
 Minimally replicated blocks:	1 (100.0 %)
 Over-replicated blocks:	0 (0.0 %)
 Under-replicated blocks:	1 (100.0 %)
 Mis-replicated blocks:		0 (0.0 %)
 Default replication factor:	1
 Average block replication:	1.0
 Corrupt blocks:		0
 Missing replicas:		2 (66.666664 %)
 Number of data-nodes:		1
 Number of racks:		1
FSCK ended at Tue Jan 07 03:28:09 PST 2025 in 14 milliseconds


The filesystem under path '/user/cloudera/fileDeletionCheck' is HEALTHY
[cloudera@quickstart ~]$ hadoop fsck /user/cloudera/fileDeletionCheck -racks
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

Connecting to namenode via http://quickstart.cloudera:50070/fsck?ugi=cloudera&racks=1&path=%2Fuser%2Fcloudera%2FfileDeletionCheck
FSCK started by cloudera (auth:SIMPLE) from /127.0.0.1 for path /user/cloudera/fileDeletionCheck at Tue Jan 07 03:28:36 PST 2025
.
/user/cloudera/fileDeletionCheck:  Under replicated BP-1914853243-127.0.0.1-1500467607052:blk_1073744586_3793. Target Replicas is 3 but found 1 live replica(s), 0 decommissioned replica(s), 0 decommissioning replica(s).
Status: HEALTHY
 Total size:	44 B
 Total dirs:	0
 Total files:	1
 Total symlinks:		0
 Total blocks (validated):	1 (avg. block size 44 B)
 Minimally replicated blocks:	1 (100.0 %)
 Over-replicated blocks:	0 (0.0 %)
 Under-replicated blocks:	1 (100.0 %)
 Mis-replicated blocks:		0 (0.0 %)
 Default replication factor:	1
 Average block replication:	1.0
 Corrupt blocks:		0
 Missing replicas:		2 (66.666664 %)
 Number of data-nodes:		1
 Number of racks:		1
FSCK ended at Tue Jan 07 03:28:36 PST 2025 in 9 milliseconds


The filesystem under path '/user/cloudera/fileDeletionCheck' is HEALTHY
[cloudera@quickstart ~]$ hadoop fsck /user/cloudera/fileDeletionCheck -details
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

fsck: Illegal option '-details'
Usage: DFSck <path> [-list-corruptfileblocks | [-move | -delete | -openforwrite] [-files [-blocks [-locations | -racks]]]] [-maintenance]
	<path>	start checking from this path
	-move	move corrupted files to /lost+found
	-delete	delete corrupted files
	-files	print out files being checked
	-openforwrite	print out files opened for write
	-includeSnapshots	include snapshot data if the given path indicates a snapshottable directory or there are snapshottable directories under it
	-list-corruptfileblocks	print out list of missing blocks and files they belong to
	-blocks	print out block report
	-locations	print out locations for every block
	-racks	print out network topology for data-node locations

	-maintenance	print out maintenance state node details
	-blockId	print out which file this blockId belongs to, locations (nodes, racks) of this block, and other diagnostics info (under replicated, corrupted or not, etc)

Please Note:
	1. By default fsck ignores files opened for write, use -openforwrite to report such files. They are usually  tagged CORRUPT or HEALTHY depending on their block allocation status
	2. Option -includeSnapshots should not be used for comparing stats, should be used only for HEALTH check, as this may contain duplicates if the same file present in both original fs tree and inside snapshots.

Generic options supported are
-conf <configuration file>     specify an application configuration file
-D <property=value>            use value for given property
-fs <local|namenode:port>      specify a namenode
-jt <local|resourcemanager:port>    specify a ResourceManager
-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster
-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.

The general command line syntax is
bin/hadoop command [genericOptions] [commandOptions]

[cloudera@quickstart ~]$ hadoop fsck /user/cloudera/fileDeletionCheck -list-corruptfileblocks
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

Connecting to namenode via http://quickstart.cloudera:50070/fsck?ugi=cloudera&listcorruptfileblocks=1&path=%2Fuser%2Fcloudera%2FfileDeletionCheck
The filesystem under path '/user/cloudera/fileDeletionCheck' has 0 CORRUPT files
[cloudera@quickstart ~]$ hadoop fsck /user/cloudera/fileDeletionCheck -list-corruptfileblocks -limit 10
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

fsck: Illegal option '-limit'
Usage: DFSck <path> [-list-corruptfileblocks | [-move | -delete | -openforwrite] [-files [-blocks [-locations | -racks]]]] [-maintenance]
	<path>	start checking from this path
	-move	move corrupted files to /lost+found
	-delete	delete corrupted files
	-files	print out files being checked
	-openforwrite	print out files opened for write
	-includeSnapshots	include snapshot data if the given path indicates a snapshottable directory or there are snapshottable directories under it
	-list-corruptfileblocks	print out list of missing blocks and files they belong to
	-blocks	print out block report
	-locations	print out locations for every block
	-racks	print out network topology for data-node locations

	-maintenance	print out maintenance state node details
	-blockId	print out which file this blockId belongs to, locations (nodes, racks) of this block, and other diagnostics info (under replicated, corrupted or not, etc)

Please Note:
	1. By default fsck ignores files opened for write, use -openforwrite to report such files. They are usually  tagged CORRUPT or HEALTHY depending on their block allocation status
	2. Option -includeSnapshots should not be used for comparing stats, should be used only for HEALTH check, as this may contain duplicates if the same file present in both original fs tree and inside snapshots.

Generic options supported are
-conf <configuration file>     specify an application configuration file
-D <property=value>            use value for given property
-fs <local|namenode:port>      specify a namenode
-jt <local|resourcemanager:port>    specify a ResourceManager
-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster
-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.

The general command line syntax is
bin/hadoop command [genericOptions] [commandOptions]

[cloudera@quickstart ~]$ hadoop fsck /user/cloudera/fileDeletionCheck -replication=3
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

fsck: Illegal option '-replication=3'
Usage: DFSck <path> [-list-corruptfileblocks | [-move | -delete | -openforwrite] [-files [-blocks [-locations | -racks]]]] [-maintenance]
	<path>	start checking from this path
	-move	move corrupted files to /lost+found
	-delete	delete corrupted files
	-files	print out files being checked
	-openforwrite	print out files opened for write
	-includeSnapshots	include snapshot data if the given path indicates a snapshottable directory or there are snapshottable directories under it
	-list-corruptfileblocks	print out list of missing blocks and files they belong to
	-blocks	print out block report
	-locations	print out locations for every block
	-racks	print out network topology for data-node locations

	-maintenance	print out maintenance state node details
	-blockId	print out which file this blockId belongs to, locations (nodes, racks) of this block, and other diagnostics info (under replicated, corrupted or not, etc)

Please Note:
	1. By default fsck ignores files opened for write, use -openforwrite to report such files. They are usually  tagged CORRUPT or HEALTHY depending on their block allocation status
	2. Option -includeSnapshots should not be used for comparing stats, should be used only for HEALTH check, as this may contain duplicates if the same file present in both original fs tree and inside snapshots.

Generic options supported are
-conf <configuration file>     specify an application configuration file
-D <property=value>            use value for given property
-fs <local|namenode:port>      specify a namenode
-jt <local|resourcemanager:port>    specify a ResourceManager
-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster
-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.

The general command line syntax is
bin/hadoop command [genericOptions] [commandOptions]

[cloudera@quickstart ~]$ #what if I need to set block size or replication  or buffer size or timeout at the time of data transfer from local to hdfs location, below commands will helps to do that.. 
[cloudera@quickstart ~]$ 
[cloudera@quickstart ~]$ hadoop fs -ls /user/cloudera
Found 7 items
-rw-r--r--   1 cloudera supergroup          0 2025-01-07 02:11 /user/cloudera/datafile
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:09 /user/cloudera/file1
-rw-r--r--   3 cloudera supergroup         44 2025-01-07 02:33 /user/cloudera/fileDeletionCheck
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 03:05 /user/cloudera/folder1
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:08 /user/cloudera/folder2
-rw-r--r--   1 cloudera supergroup         86 2025-01-07 02:28 /user/cloudera/mydata2
drwxr-xr-x   - cloudera supergroup          0 2025-01-07 02:18 /user/cloudera/myfile
[cloudera@quickstart ~]$ hadoop fs -mkdir /user/cloudera/datatransfer
[cloudera@quickstart ~]$ hadoop fs -Ddfs.blocksize=256m -put /home/cloudera/fileDeletionCheck /user/cloudera/datatransfer
[cloudera@quickstart ~]$ hadoop fs -stat %o /user/cloudera/datatransfer/fileDeletionCheck
268435456
[cloudera@quickstart ~]$ #268435456 === 256MB
[cloudera@quickstart ~]$ #-Ddfs.replication=3 -put local_path hdfs_path 
[cloudera@quickstart ~]$ 
[cloudera@quickstart ~]$ 
[cloudera@quickstart ~]$ 
[cloudera@quickstart ~]$ #end of hadoopppppppp...............
Message from syslogd@quickstart at Jan  7 04:07:54 ...
 kernel:BUG: soft lockup - CPU#0 stuck for 259s! [java:7453]

[cloudera@quickstart ~]$  
